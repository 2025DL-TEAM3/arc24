# Iteration 14. Speedup training with unsloth

_01-09-2024_

## Goal

Can we speedup training using [unsloth](https://github.com/unslothai/unsloth)?

## Motivation

On previous iterations I have tried using different learning rate schedules to speedup the training, or changing
the batch size without success. [Unsloth library](https://github.com/unslothai/unsloth) might be an easy way to speedup training.

If I'm able to speedup training I will be able to train faster, but at the same time I could do longer
test-time fine-tuning when making a submission.

Hopefully this will be a very fast iteration.

## Development

## Results

## Conclusion

## Next steps

## TODO

- [ ]
