{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write python code for training tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write python code that implements training tasks and also creates the input distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyperclip\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# add path to python path\n",
    "sys.path.append(os.path.realpath('../scripts/'))\n",
    "from arc24.data import load_arc_data_with_solutions\n",
    "from evaluation import plot_grids, plot_grid, plot_task\n",
    "from arc24.logging import logging\n",
    "from arc24.data_augmentation import apply_data_augmentation, get_random_color_map, get_random_geometric_augmentation_params\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sys.path.append(os.path.realpath('../arc'))\n",
    "import training_inputs\n",
    "import training_tasks\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 2)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = load_arc_data_with_solutions('/mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json')\n",
    "train_data = load_arc_data_with_solutions('/mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grids_with_shape(grids, suptitle=None, facecolor='white'):\n",
    "    plt.figure(facecolor=facecolor)\n",
    "    for plot_idx, grid in enumerate(grids):\n",
    "        plt.subplot(1, len(grids), plot_idx + 1)\n",
    "        plot_grid(grid)\n",
    "        plt.title(f'{len(grid)}x{len(grid[0])}')\n",
    "    if suptitle is not None:\n",
    "        # plt.suptitle(suptitle)\n",
    "        # plt.tight_layout(pad=0.2)\n",
    "        print(suptitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_task(task_id):\n",
    "    function_intro = f'def task_{task_id}(grid):'\n",
    "    print(function_intro)\n",
    "    pyperclip.copy(function_intro)\n",
    "\n",
    "    inputs = [sample['input'] for sample in train_data[task_id]['train'] + train_data[task_id]['test']]\n",
    "    outputs = [sample['output'] for sample in train_data[task_id]['train'] + train_data[task_id]['test']]\n",
    "    plot_grids_with_shape(inputs, 'Task Inputs')\n",
    "    plot_grids_with_shape(outputs, 'Ground truth Outputs', facecolor='gray')\n",
    "\n",
    "    try:\n",
    "        inputs = [getattr(training_inputs, f'task_{task_id}')() for _ in range(5)]\n",
    "        plot_grids_with_shape(inputs, 'Generated Inputs')\n",
    "    except AttributeError:\n",
    "        logger.warning('Input generation function not found')\n",
    "    except (NameError, NotImplementedError):\n",
    "        logger.warning('Input generation is implemented, but it is calling not implemented functions')\n",
    "    try:\n",
    "        outputs = [getattr(training_tasks, f'task_{task_id}')(i) for i in inputs]\n",
    "        plot_grids_with_shape(outputs, 'Generated Outputs', facecolor='gray')\n",
    "    except AttributeError:\n",
    "        logger.warning('Task function not found')\n",
    "    except (NameError, NotImplementedError):\n",
    "        logger.warning('Task function is implemented, but it is calling not implemented functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the colors and the corresponding positions\n",
    "colors = [(1, 0, 0), (1, 1, 0), (0, 1, 0)]  # Red, Yellow, Green\n",
    "positions = [0, 0.5, 1]  # At 0 -> red, 0.5 -> yellow, 1 -> green\n",
    "# Create the colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", list(zip(positions, colors)))\n",
    "\n",
    "def measure_progress(module):\n",
    "    progress = []\n",
    "    task_ids = list(train_data.keys())\n",
    "    for task_id in task_ids:\n",
    "        try:\n",
    "            task_function = getattr(module, f'task_{task_id}')\n",
    "            function_parameters = inspect.signature(task_function).parameters\n",
    "            if function_parameters:\n",
    "                task_function(**create_dummy_parameters(function_parameters))\n",
    "            else:\n",
    "                task_function()\n",
    "            progress.append('done')\n",
    "        except AttributeError as e:\n",
    "            progress.append('not implemented')\n",
    "        except (NameError, NotImplementedError):\n",
    "            progress.append('implemented but not functional')\n",
    "    numeric_progress = map({'done': 1, 'not implemented': 0, 'implemented but not functional': 0.5}.get, progress)\n",
    "    numeric_progress = np.array(list(numeric_progress))\n",
    "    print(f'Fully functional tasks: {np.mean(numeric_progress == 1):.1%} ({np.sum(numeric_progress == 1)})')\n",
    "    print(f'Implemented tasks: {np.mean(numeric_progress > 0):.1%} ({np.sum(numeric_progress > 0)})')\n",
    "    plt.imshow(np.array(list(numeric_progress)).reshape(1, -1), cmap=custom_cmap, aspect='auto')\n",
    "\n",
    "def create_dummy_parameters(function_parameters):\n",
    "    kwargs = {}\n",
    "    if 'grid' in function_parameters:\n",
    "        kwargs['grid'] = np.eye(3, dtype=int).tolist()\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid([np.arange(10).tolist()], write_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_train_task(task_id=list(train_data.keys())[0]) #69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_progress(training_tasks); plt.title('Task implementation progress');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_progress(training_inputs); plt.title('Input generation progress');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def study_data_augmentation(task_id, use_data_augmentation=True):\n",
    "    if task_id.startswith('task_'): task_id = task_id[5:]\n",
    "    print(f'Task {task_id}')\n",
    "\n",
    "    task = train_data[task_id]\n",
    "    source_code = inspect.getsource(getattr(training_tasks, f'task_{task_id}'))\n",
    "    if use_data_augmentation:\n",
    "        color_map = get_random_color_map()\n",
    "        geometric_augmentation_params = get_random_geometric_augmentation_params()\n",
    "        task = apply_data_augmentation(\n",
    "            task, color_map=color_map, **geometric_augmentation_params)\n",
    "        source_code = update_source_code_to_data_augmentation(source_code, color_map, geometric_augmentation_params)\n",
    "\n",
    "    plt.figure(figsize=(25, 4)); plot_task(task); plt.show()\n",
    "    formatted_source_code = f\"```python\\n{source_code}\\n```\\n\"\n",
    "    display(Markdown(formatted_source_code))\n",
    "\n",
    "def update_source_code_to_data_augmentation(code, color_map, geometric_augmentation_params):\n",
    "    # TODO: deal with horizontal flip\n",
    "    if geometric_augmentation_params['n_rot90'] in [1, 3]:\n",
    "        code = swap_axes(code)\n",
    "    code = update_code_to_colormap(code, color_map)\n",
    "    code = remove_comments(code)\n",
    "    return code\n",
    "\n",
    "def swap_axes(text):\n",
    "    # Use regex to find 'axis=0' or 'axis=1' and swap them\n",
    "    new_text = ''\n",
    "    for line in text.splitlines():\n",
    "        if line.endswith('# skip-augmentation'):\n",
    "            new_text += line + '\\n'\n",
    "            continue\n",
    "        new_text += re.sub(r'axis=(\\d)', lambda match: 'axis=1' if match.group(1) == '0' else 'axis=0', line) + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def update_code_to_colormap(text, color_map):\n",
    "    text = replace_colors(text, color_map)\n",
    "    text = update_color_map(text, color_map)\n",
    "    return text\n",
    "    new_text = ''\n",
    "    # for line in text.splitlines():\n",
    "    #     if line.endswith('# skip-augmentation'):\n",
    "    #         new_text += line + '\\n'\n",
    "    #         continue\n",
    "    #     new_text += re.sub(r'cmap=.*', f\"cmap='{color_map}'\", line) + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def replace_colors(text, color_map):\n",
    "    # Regex to match any digit after an equal sign and optional spaces (e.g., color=2, moving_object_color = 2)\n",
    "    return re.sub(r'=\\s*(\\d+)', lambda match: f\"= {color_map.get(int(match.group(1)), match.group(1))}\", text)\n",
    "\n",
    "\n",
    "\n",
    "def update_color_map(text, aug_color_map):\n",
    "    # Define a function that will update each pair in the color_map\n",
    "    def replace_color_map(match):\n",
    "        # Extract the color_map string from the match\n",
    "        color_map_str = match.group(1)\n",
    "        # Evaluate the color_map string into a Python dictionary\n",
    "        original_color_map = eval(f\"{{{color_map_str}}}\")\n",
    "        \n",
    "        # Create a new updated color_map based on the augmentation map\n",
    "        updated_color_map = {aug_color_map.get(k, k): aug_color_map.get(v, v) for k, v in original_color_map.items()}\n",
    "        \n",
    "        # Return the updated color_map in string format\n",
    "        return f'color_map={updated_color_map}'\n",
    "\n",
    "    # Regex to match the color_map={...} pattern\n",
    "    updated_text = re.sub(r'color_map=\\{([^}]+)\\}', replace_color_map, text)\n",
    "    \n",
    "    return updated_text\n",
    "\n",
    "\n",
    "def remove_comments(text):\n",
    "    new_text = ''\n",
    "    for line in text.splitlines():\n",
    "        new_text += re.sub(r'#.*', '', line) + '\\n'\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_data_augmentation(task_id='task_05f2a901', use_data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid([np.arange(10).tolist()], write_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pipeline_into_single_function(pipeline):\n",
    "    code = 'def pipeline(grid):\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pipeline_code(pipeline):\n",
    "    import inspect\n",
    "    from functools import partial\n",
    "\n",
    "    code_lines = []\n",
    "    code_lines.append('def pipeline(grid):')\n",
    "    indent = '    '\n",
    "    first_function = True\n",
    "    for p in pipeline:\n",
    "        # Determine if p is a partial function or a regular function\n",
    "        if isinstance(p, partial):\n",
    "            func = p.func\n",
    "            args = p.args\n",
    "            keywords = p.keywords\n",
    "        else:\n",
    "            func = p\n",
    "            args = ()\n",
    "            keywords = {}\n",
    "\n",
    "        # Assign parameter values from partial function\n",
    "        for param_name, value in keywords.items():\n",
    "            code_lines.append(f'{indent}{param_name} = {repr(value)}')\n",
    "\n",
    "        # Get source code of the function\n",
    "        source = inspect.getsource(func)\n",
    "        source_lines = source.strip().split('\\n')\n",
    "\n",
    "        # Remove the 'def' line\n",
    "        body_lines = source_lines[1:]\n",
    "\n",
    "        # Adjust indentation and remove 'return' statements\n",
    "        body_lines = [\n",
    "            line.lstrip()\n",
    "            for line in body_lines\n",
    "            if not line.strip().startswith('return')\n",
    "        ]\n",
    "\n",
    "        # Determine input variable\n",
    "        input_var = func.__code__.co_varnames[0]\n",
    "        if first_function:\n",
    "            input_var_in_code = 'grid'\n",
    "            first_function = False\n",
    "        else:\n",
    "            input_var_in_code = 'output'\n",
    "\n",
    "        # Replace input variable names in the function body\n",
    "        body_lines = [\n",
    "            line.replace(input_var, input_var_in_code)\n",
    "            for line in body_lines\n",
    "        ]\n",
    "\n",
    "        # Append the function body to code_lines\n",
    "        for line in body_lines:\n",
    "            code_lines.append(indent + line)\n",
    "\n",
    "    # Add the final return statement\n",
    "    code_lines.append(f'{indent}return output')\n",
    "\n",
    "    # Join all lines into a single string\n",
    "    return '\\n'.join(code_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_pipeline_code(pipeline = [partial(rotate, angle=90), partial(flip, axis=0)]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rotate(grid, angle):\n",
    "    # Rotate the grid by the given angle (90, 180, 270)\n",
    "    output = np.rot90(grid, k=angle // 90)\n",
    "    for _ in range(2):\n",
    "        print('hello')\n",
    "    return output\n",
    "\n",
    "def flip(grid, axis):\n",
    "    # Flip the grid horizontally or vertically\n",
    "    output = np.flip(grid, axis)\n",
    "    return output\n",
    "\n",
    "# pipeline.py\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, *functions):\n",
    "        self.functions = functions\n",
    "\n",
    "    def apply(self, grid):\n",
    "        for func in self.functions:\n",
    "            grid = func(grid)\n",
    "        return grid\n",
    "\n",
    "    def generate_code(self):\n",
    "        code_lines = []\n",
    "        for func in self.functions:\n",
    "            code = inspect.getsource(func)\n",
    "            code_lines.append(code)\n",
    "        return '\\n'.join(code_lines)\n",
    "\n",
    "# code_generator.py\n",
    "\n",
    "def combine_functions(pipeline):\n",
    "    code_lines = ['def transform(grid):']\n",
    "    indent = '    '\n",
    "    code_lines.append(f'{indent}import copy')\n",
    "    code_lines.append(f'{indent}grid = copy.deepcopy(grid)')\n",
    "    for func in pipeline.functions:\n",
    "        func_code = inspect.getsource(func).split('\\n')\n",
    "        func_code = [indent + line for line in func_code if not line.startswith('def')]\n",
    "        code_lines.extend(func_code)\n",
    "        func_call = f'{indent}grid = {func.__name__}(grid)'\n",
    "        code_lines.append(func_call)\n",
    "    code_lines.append(f'{indent}return grid')\n",
    "    return '\\n'.join(code_lines)\n",
    "\n",
    "functions = Pipeline(rotate, flip)\n",
    "print(functions.generate_code())\n",
    "\n",
    "print(combine_functions(functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease the process of combining the functions into a single function I will use by convention the same variable for input and output: `grid`\n",
    "\n",
    "Additionally always use keywords on partial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "from functools import partial\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def rotate(grid, angle):\n",
    "    grid = np.rot90(grid, k=angle // 90)\n",
    "    return grid\n",
    "\n",
    "def flip(grid, axis):\n",
    "    grid = np.flip(grid, axis)\n",
    "    return grid\n",
    "\n",
    "def foo(grid):\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pipeline_code(pipeline):\n",
    "    code_lines = []\n",
    "    code_lines.append('def pipeline(grid):')\n",
    "    indent = '    '\n",
    "    for p in pipeline:\n",
    "        # Determine if p is a partial function or a regular function\n",
    "        if isinstance(p, partial):\n",
    "            func = p.func\n",
    "            keywords = p.keywords\n",
    "        else:\n",
    "            func = p\n",
    "            keywords = {}\n",
    "\n",
    "        # Assign parameter values from partial function\n",
    "        for param_name, value in keywords.items():\n",
    "            code_lines.append(f'{indent}{param_name} = {repr(value)}')\n",
    "\n",
    "        # Get source code of the function\n",
    "        source = inspect.getsource(func)\n",
    "        source_lines = source.strip().split('\\n')\n",
    "\n",
    "        # Remove the 'def' and 'return' lines\n",
    "        body_lines = source_lines[1:-1]\n",
    "        code_lines.extend(body_lines)\n",
    "\n",
    "    # Add the final return statement\n",
    "    code_lines.append(f'{indent}return grid')\n",
    "\n",
    "    # Join all lines into a single string\n",
    "    return '\\n'.join(code_lines)\n",
    "\n",
    "code = generate_pipeline_code(pipeline = [\n",
    "    partial(rotate, angle=90),\n",
    "    partial(flip, axis=0),\n",
    "    foo])\n",
    "display(Markdown(f'```python\\n{code}\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good and it could work, I just have to be careful with the code. I might test that all the functions follow that criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_function_follows_convention(function):\n",
    "    assert inspect.getsource(function).splitlines()[-1].endswith('return grid')\n",
    "    assert 'grid' in inspect.signature(function).parameters\n",
    "\n",
    "[verify_function_follows_convention(function) for function in [rotate, flip, foo]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could also automatically test that the code generated by combining the functions of the pipeline gives the same results as the code from the pipeline. Functions need to be deterministic to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inspect\n",
    "from functools import partial\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, *functions):\n",
    "        self.functions = functions\n",
    "        [verify_function_follows_convention(function) for function in functions]\n",
    "\n",
    "    def apply(self, grid):\n",
    "        grid = np.array(grid, dtype=np.int8)\n",
    "        for func in self.functions:\n",
    "            grid = func(grid)\n",
    "        grid = grid.tolist()\n",
    "        return grid\n",
    "\n",
    "    def generate_code(self):\n",
    "        # TODO: maybe assign a name to the pipeline function\n",
    "        return generate_pipeline_code(self.functions)\n",
    "\n",
    "def generate_pipeline_code(functions, function_name='pipeline', parameter_name='grid'):\n",
    "    code_lines = []\n",
    "    code_lines.append(f'def {function_name}({parameter_name}):')\n",
    "    indent = '    '\n",
    "    for function in functions:\n",
    "        if isinstance(function, partial):\n",
    "            keywords = function.keywords\n",
    "            function = function.func\n",
    "        else:\n",
    "            keywords = {key: value.default for key, value in inspect.signature(function).parameters.items() if key != parameter_name}\n",
    "        for param_name, value in keywords.items():\n",
    "            code_lines.append(f'{indent}{param_name} = {repr(value)}')\n",
    "\n",
    "        source = inspect.getsource(function)\n",
    "        source_lines = source.strip().split('\\n')\n",
    "        body_lines = source_lines[1:-1] # Remove the 'def' and 'return' lines\n",
    "        code_lines.extend(body_lines)\n",
    "\n",
    "    # Add the final return statement\n",
    "    code_lines.append(f'{indent}return {parameter_name}')\n",
    "    return '\\n'.join(code_lines)\n",
    "\n",
    "def verify_function_follows_convention(function):\n",
    "    \"\"\" All functions in the pipeline should follow the convention of taking a grid as input and returning a grid \"\"\"\n",
    "    if isinstance(function, partial):\n",
    "        function = function.func\n",
    "    assert inspect.getsource(function).splitlines()[-1].endswith('return grid')\n",
    "    assert 'grid' in inspect.signature(function).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(grid, angle):\n",
    "    grid = np.rot90(grid, k=angle // 90)\n",
    "    return grid\n",
    "\n",
    "def flip(grid, axis):\n",
    "    grid = np.flip(grid, axis)\n",
    "    return grid\n",
    "\n",
    "def foo(grid, n=10):\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    partial(rotate, angle=90),\n",
    "    partial(flip, axis=0),\n",
    "    foo)\n",
    "code = pipeline.generate_code()\n",
    "display(Markdown(f'```python\\n{code}\\n```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    partial(rotate, angle=90),)\n",
    "code = pipeline.generate_code()\n",
    "display(Markdown(f'```python\\n{code}\\n```'))\n",
    "pipeline.apply(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task():\n",
    "    def __init__(self, input_generator, input_augmentation, task_pipeline):\n",
    "        self.input_generator = input_generator\n",
    "        self.input_augmentation = input_augmentation\n",
    "        self.task_pipeline = task_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Create stats about the progress of the tasks implementation\n",
    "- [ ] Is the implementation robust to data augmentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
