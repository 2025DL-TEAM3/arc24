{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write python code for training tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write python code that implements training tasks and also creates the input distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyperclip\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# add path to python path\n",
    "sys.path.append(os.path.realpath('../scripts/'))\n",
    "from arc24.data import load_arc_data_with_solutions\n",
    "from evaluation import plot_grids, plot_grid, plot_task\n",
    "from arc24.logging import logging\n",
    "from arc24.data_augmentation import apply_data_augmentation, get_random_color_map, get_random_geometric_augmentation_params\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sys.path.append(os.path.realpath('../arc'))\n",
    "import training_inputs\n",
    "import training_tasks\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 2)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = load_arc_data_with_solutions('/mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json')\n",
    "train_data = load_arc_data_with_solutions('/mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grids_with_shape(grids, suptitle=None, facecolor='white'):\n",
    "    plt.figure(facecolor=facecolor)\n",
    "    for plot_idx, grid in enumerate(grids):\n",
    "        plt.subplot(1, len(grids), plot_idx + 1)\n",
    "        plot_grid(grid)\n",
    "        plt.title(f'{len(grid)}x{len(grid[0])}')\n",
    "    if suptitle is not None:\n",
    "        # plt.suptitle(suptitle)\n",
    "        # plt.tight_layout(pad=0.2)\n",
    "        print(suptitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_task(task_id):\n",
    "    function_intro = f'def task_{task_id}(grid):'\n",
    "    print(function_intro)\n",
    "    pyperclip.copy(function_intro)\n",
    "\n",
    "    inputs = [sample['input'] for sample in train_data[task_id]['train'] + train_data[task_id]['test']]\n",
    "    outputs = [sample['output'] for sample in train_data[task_id]['train'] + train_data[task_id]['test']]\n",
    "    plot_grids_with_shape(inputs, 'Task Inputs')\n",
    "    plot_grids_with_shape(outputs, 'Ground truth Outputs', facecolor='gray')\n",
    "\n",
    "    try:\n",
    "        inputs = [getattr(training_inputs, f'task_{task_id}')() for _ in range(5)]\n",
    "        plot_grids_with_shape(inputs, 'Generated Inputs')\n",
    "    except AttributeError:\n",
    "        logger.warning('Input generation function not found')\n",
    "    except (NameError, NotImplementedError):\n",
    "        logger.warning('Input generation is implemented, but it is calling not implemented functions')\n",
    "    try:\n",
    "        outputs = [getattr(training_tasks, f'task_{task_id}')(i) for i in inputs]\n",
    "        plot_grids_with_shape(outputs, 'Generated Outputs', facecolor='gray')\n",
    "    except AttributeError:\n",
    "        logger.warning('Task function not found')\n",
    "    except (NameError, NotImplementedError):\n",
    "        logger.warning('Task function is implemented, but it is calling not implemented functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the colors and the corresponding positions\n",
    "colors = [(1, 0, 0), (1, 1, 0), (0, 1, 0)]  # Red, Yellow, Green\n",
    "positions = [0, 0.5, 1]  # At 0 -> red, 0.5 -> yellow, 1 -> green\n",
    "# Create the colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", list(zip(positions, colors)))\n",
    "\n",
    "def measure_progress(module):\n",
    "    progress = []\n",
    "    task_ids = list(train_data.keys())\n",
    "    for task_id in task_ids:\n",
    "        try:\n",
    "            task_function = getattr(module, f'task_{task_id}')\n",
    "            function_parameters = inspect.signature(task_function).parameters\n",
    "            if function_parameters:\n",
    "                task_function(**create_dummy_parameters(function_parameters))\n",
    "            else:\n",
    "                task_function()\n",
    "            progress.append('done')\n",
    "        except AttributeError as e:\n",
    "            progress.append('not implemented')\n",
    "        except (NameError, NotImplementedError):\n",
    "            progress.append('implemented but not functional')\n",
    "    numeric_progress = map({'done': 1, 'not implemented': 0, 'implemented but not functional': 0.5}.get, progress)\n",
    "    numeric_progress = np.array(list(numeric_progress))\n",
    "    print(f'Fully functional tasks: {np.mean(numeric_progress == 1):.1%} ({np.sum(numeric_progress == 1)})')\n",
    "    print(f'Implemented tasks: {np.mean(numeric_progress > 0):.1%} ({np.sum(numeric_progress > 0)})')\n",
    "    plt.imshow(np.array(list(numeric_progress)).reshape(1, -1), cmap=custom_cmap, aspect='auto')\n",
    "\n",
    "def create_dummy_parameters(function_parameters):\n",
    "    kwargs = {}\n",
    "    if 'grid' in function_parameters:\n",
    "        kwargs['grid'] = np.eye(3, dtype=int).tolist()\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid([np.arange(10).tolist()], write_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_train_task(task_id=list(train_data.keys())[0]) #69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_progress(training_tasks); plt.title('Task implementation progress');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_progress(training_inputs); plt.title('Input generation progress');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def study_data_augmentation(task_id, use_data_augmentation=True):\n",
    "    if task_id.startswith('task_'): task_id = task_id[5:]\n",
    "    print(f'Task {task_id}')\n",
    "\n",
    "    task = train_data[task_id]\n",
    "    source_code = inspect.getsource(getattr(training_tasks, f'task_{task_id}'))\n",
    "    if use_data_augmentation:\n",
    "        color_map = get_random_color_map()\n",
    "        geometric_augmentation_params = get_random_geometric_augmentation_params()\n",
    "        task = apply_data_augmentation(\n",
    "            task, color_map=color_map, **geometric_augmentation_params)\n",
    "        source_code = update_source_code_to_data_augmentation(source_code, color_map, geometric_augmentation_params)\n",
    "\n",
    "    plt.figure(figsize=(25, 4)); plot_task(task); plt.show()\n",
    "    formatted_source_code = f\"```python\\n{source_code}\\n```\\n\"\n",
    "    display(Markdown(formatted_source_code))\n",
    "\n",
    "def update_source_code_to_data_augmentation(code, color_map, geometric_augmentation_params):\n",
    "    # TODO: deal with horizontal flip\n",
    "    if geometric_augmentation_params['n_rot90'] in [1, 3]:\n",
    "        code = swap_axes(code)\n",
    "    code = update_code_to_colormap(code, color_map)\n",
    "    code = remove_comments(code)\n",
    "    return code\n",
    "\n",
    "def swap_axes(text):\n",
    "    # Use regex to find 'axis=0' or 'axis=1' and swap them\n",
    "    new_text = ''\n",
    "    for line in text.splitlines():\n",
    "        if line.endswith('# skip-augmentation'):\n",
    "            new_text += line + '\\n'\n",
    "            continue\n",
    "        new_text += re.sub(r'axis=(\\d)', lambda match: 'axis=1' if match.group(1) == '0' else 'axis=0', line) + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def update_code_to_colormap(text, color_map):\n",
    "    text = replace_colors(text, color_map)\n",
    "    text = update_color_map(text, color_map)\n",
    "    return text\n",
    "    new_text = ''\n",
    "    # for line in text.splitlines():\n",
    "    #     if line.endswith('# skip-augmentation'):\n",
    "    #         new_text += line + '\\n'\n",
    "    #         continue\n",
    "    #     new_text += re.sub(r'cmap=.*', f\"cmap='{color_map}'\", line) + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def replace_colors(text, color_map):\n",
    "    # Regex to match any digit after an equal sign and optional spaces (e.g., color=2, moving_object_color = 2)\n",
    "    return re.sub(r'=\\s*(\\d+)', lambda match: f\"= {color_map.get(int(match.group(1)), match.group(1))}\", text)\n",
    "\n",
    "\n",
    "\n",
    "def update_color_map(text, aug_color_map):\n",
    "    # Define a function that will update each pair in the color_map\n",
    "    def replace_color_map(match):\n",
    "        # Extract the color_map string from the match\n",
    "        color_map_str = match.group(1)\n",
    "        # Evaluate the color_map string into a Python dictionary\n",
    "        original_color_map = eval(f\"{{{color_map_str}}}\")\n",
    "        \n",
    "        # Create a new updated color_map based on the augmentation map\n",
    "        updated_color_map = {aug_color_map.get(k, k): aug_color_map.get(v, v) for k, v in original_color_map.items()}\n",
    "        \n",
    "        # Return the updated color_map in string format\n",
    "        return f'color_map={updated_color_map}'\n",
    "\n",
    "    # Regex to match the color_map={...} pattern\n",
    "    updated_text = re.sub(r'color_map=\\{([^}]+)\\}', replace_color_map, text)\n",
    "    \n",
    "    return updated_text\n",
    "\n",
    "\n",
    "def remove_comments(text):\n",
    "    new_text = ''\n",
    "    for line in text.splitlines():\n",
    "        new_text += re.sub(r'#.*', '', line) + '\\n'\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_data_augmentation(task_id='task_05f2a901', use_data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid([np.arange(10).tolist()], write_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Create stats about the progress of the tasks implementation\n",
    "- [ ] Is the implementation robust to data augmentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
