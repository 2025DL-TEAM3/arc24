{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2dff18",
   "metadata": {
    "papermill": {
     "duration": 0.016731,
     "end_time": "2024-08-08T16:39:23.941866",
     "exception": false,
     "start_time": "2024-08-08T16:39:23.925135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuned LLMs for ARC24 Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9727c3",
   "metadata": {
    "papermill": {
     "duration": 0.013703,
     "end_time": "2024-08-08T16:39:23.970635",
     "exception": false,
     "start_time": "2024-08-08T16:39:23.956932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84664d",
   "metadata": {
    "papermill": {
     "duration": 0.014588,
     "end_time": "2024-08-08T16:39:23.998930",
     "exception": false,
     "start_time": "2024-08-08T16:39:23.984342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How far can we get with LLMs on ARC24 challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b75a5",
   "metadata": {
    "papermill": {
     "duration": 0.013547,
     "end_time": "2024-08-08T16:39:24.026462",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.012915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Can I reach the same accuracy with single prompt as with the dialog in the previous notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d923770",
   "metadata": {
    "papermill": {
     "duration": 0.013668,
     "end_time": "2024-08-08T16:39:24.053892",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.040224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78874c2",
   "metadata": {
    "papermill": {
     "duration": 0.013774,
     "end_time": "2024-08-08T16:39:24.081712",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.067938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "On my previous [Few-shot prompting for ARC24](https://www.kaggle.com/code/ironbar/few-shot-prompting-for-arc24) I found that current \"small\" open-source LLMs do not benefit from few-shot prompting for ARC challenge. \n",
    "\n",
    "On this notebook I'm going to focus on the 0-shot approach: the model will only receive the input-output examples from the task of interest (no information from other tasks).\n",
    "\n",
    "This notebook will allow to evaluate and submit different LLMs on ARC tasks. It will open the door to use fine-tuned models and also to use the misterious \"test time fine-tuning\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaead0d7",
   "metadata": {
    "papermill": {
     "duration": 0.014257,
     "end_time": "2024-08-08T16:39:24.110447",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.096190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20d657",
   "metadata": {
    "papermill": {
     "duration": 0.014518,
     "end_time": "2024-08-08T16:39:24.139404",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.124886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1149b0",
   "metadata": {
    "papermill": {
     "duration": 0.014978,
     "end_time": "2024-08-08T16:39:24.168417",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.153439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d95df9",
   "metadata": {
    "papermill": {
     "duration": 0.013996,
     "end_time": "2024-08-08T16:39:24.196684",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.182688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- https://www.kaggle.com/code/ironbar/2xvllm-with-code-interpreter\n",
    "- https://www.kaggle.com/code/ironbar/autobots-roll-out/notebook\n",
    "- https://www.kaggle.com/code/ironbar/few-shot-prompting-for-arc24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96541efd",
   "metadata": {
    "papermill": {
     "duration": 0.01363,
     "end_time": "2024-08-08T16:39:24.223981",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.210351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24880e2a",
   "metadata": {
    "papermill": {
     "duration": 0.013445,
     "end_time": "2024-08-08T16:39:24.251196",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.237751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\n",
    "- https://huggingface.co/blog/kv-cache-quantization\n",
    "- https://www.reddit.com/r/LocalLLaMA/comments/1e0kkgk/hardware_requirements_for_phi3_mini_and_phi3/\n",
    "- https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fmicrosoft-phi-3-3-8b-with-128k-context-released-on-hf-v0-h2xzg8vaigwc1.jpeg%3Fwidth%3D1734%26format%3Dpjpg%26auto%3Dwebp%26s%3Dec27de7bd97a90a4c44ff95c561ce8008ce7aed3\n",
    "- https://huggingface.co/docs/transformers/main/en/chat_templating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d4ff7",
   "metadata": {
    "papermill": {
     "duration": 0.013752,
     "end_time": "2024-08-08T16:39:24.278936",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.265184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> The Phi-3-Mini-128K-Instruct is a 3.8 billion-parameter, lightweight, state-of-the-art open model trained using the Phi-3 datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ccd8b9",
   "metadata": {
    "papermill": {
     "duration": 0.013885,
     "end_time": "2024-08-08T16:39:24.306967",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.293082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1895fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.337728Z",
     "iopub.status.busy": "2024-08-08T16:39:24.336953Z",
     "iopub.status.idle": "2024-08-08T16:39:24.349831Z",
     "shell.execute_reply": "2024-08-08T16:39:24.349055Z"
    },
    "papermill": {
     "duration": 0.030845,
     "end_time": "2024-08-08T16:39:24.351807",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.320962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class cfg:\n",
    "    # Model\n",
    "    model_path = \"/home/gbarbadillo/data/Qwen2-0.5B-arc\"\n",
    "    lora_path = None\n",
    "    #lora_path : Optional[str] = '/kaggle/input/loras/transformers/phi-3_128k/1'\n",
    "    merged_model_path : Optional[str] = None\n",
    "    max_model_len = 8192 #61000 for phi-3\n",
    "    # Dataset\n",
    "    dataset_path = '/mnt/hdd0/Kaggle/arc24/data/arc-agi_training_challenges.json'\n",
    "    #dataset_path = '/mnt/hdd0/Kaggle/arc24/data/arc-agi_evaluation_challenges.json'\n",
    "    n_tasks = 5 # Optional parameter to limit the number of task in the inference, set it to None to use all the tasks\n",
    "    # Inference params\n",
    "    max_predictions_per_task = 2 # \n",
    "    sampling_params = dict(temperature=0.0, max_tokens=1000) # https://docs.vllm.ai/en/latest/dev/sampling_params.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3c7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.382272Z",
     "iopub.status.busy": "2024-08-08T16:39:24.381610Z",
     "iopub.status.idle": "2024-08-08T16:39:24.451476Z",
     "shell.execute_reply": "2024-08-08T16:39:24.450439Z"
    },
    "papermill": {
     "duration": 0.087215,
     "end_time": "2024-08-08T16:39:24.453643",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.366428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful AI assistant. Your job is to solve tasks from the Abstraction and Reasoning Challenge (ARC). \n",
    "The user will present you with sample input and output grids for each task. \n",
    "Your job will be to understand the transformation between the input and the output and apply it to the last input grid given by the user. \n",
    "The puzzle-like inputs and outputs present a grid where each square can be one of ten colors. A grid can be any height or width between 1x1 and 30x30.\n",
    "The background of the grid is typically colored with 0.\n",
    "The tasks from ARC are based on the following priors:\n",
    "\n",
    "- Objectness: Objects persist and cannot appear or disappear without reason. Objects can interact or not depending on the circumstances.\n",
    "- Goal-directed: Objects can be animate or inanimate. Some objects are \"agents\" - they have intentions and they pursue goals.\n",
    "- Numbers & counting: Objects can be counted or sorted by their shape, appearance, or movement using basic mathematics like addition, subtraction, and comparison.\n",
    "- Basic geometry & topology: Objects can be shapes like rectangles, triangles, and circles which can be mirrored, rotated, translated, deformed, combined, repeated, etc. Differences in distances can be detected.\n",
    "\n",
    "The transformations between input and output should be based on these priors.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = Template(\"\"\"Let's see if you can solve this simple ARC task. These are some input-output grid examples that define the task.\n",
    "{% for sample in train_samples %}\n",
    "## Example {{ loop.index }}\n",
    "\n",
    "### Input\n",
    "\n",
    "{{ sample.input }}\n",
    "\n",
    "### Output\n",
    "\n",
    "{{ sample.output }}\n",
    "{% endfor %}\n",
    "## Test case\n",
    "\n",
    "### Input\n",
    "\n",
    "{{ test_input }}\n",
    "\"\"\")\n",
    "\n",
    "answer_template = Template(\"\"\"### Output\n",
    "\n",
    "{{ test_output }}\"\"\")\n",
    "\n",
    "train_samples = [dict(input=[0], output=[1]), dict(input=[2], output=[3])]\n",
    "prompt = prompt_template.render(train_samples=train_samples, test_input=[4])\n",
    "print(prompt)\n",
    "print(answer_template.render(test_output=[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d1174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.483966Z",
     "iopub.status.busy": "2024-08-08T16:39:24.483370Z",
     "iopub.status.idle": "2024-08-08T16:39:24.488848Z",
     "shell.execute_reply": "2024-08-08T16:39:24.487969Z"
    },
    "papermill": {
     "duration": 0.022797,
     "end_time": "2024-08-08T16:39:24.490821",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.468024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "is_dry_run = cfg.dataset_path == '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json' and not os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n",
    "if is_dry_run:\n",
    "    print('This is a dry run, no inference nor installation of packages will be done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5c1e2",
   "metadata": {
    "papermill": {
     "duration": 0.014151,
     "end_time": "2024-08-08T16:39:24.519281",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.505130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0491c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.551454Z",
     "iopub.status.busy": "2024-08-08T16:39:24.551001Z",
     "iopub.status.idle": "2024-08-08T16:39:24.560473Z",
     "shell.execute_reply": "2024-08-08T16:39:24.559459Z"
    },
    "papermill": {
     "duration": 0.027659,
     "end_time": "2024-08-08T16:39:24.562431",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.534772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not is_dry_run:\n",
    "    # model imports\n",
    "    from vllm import LLM, SamplingParams\n",
    "    from vllm.lora.request import LoRARequest\n",
    "    from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27738f0",
   "metadata": {
    "papermill": {
     "duration": 0.015015,
     "end_time": "2024-08-08T16:39:24.592948",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.577933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661345eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.624260Z",
     "iopub.status.busy": "2024-08-08T16:39:24.623789Z",
     "iopub.status.idle": "2024-08-08T16:39:24.772295Z",
     "shell.execute_reply": "2024-08-08T16:39:24.771582Z"
    },
    "papermill": {
     "duration": 0.166379,
     "end_time": "2024-08-08T16:39:24.774271",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.607892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from itertools import islice, product\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from termcolor import colored\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a12c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.842886Z",
     "iopub.status.busy": "2024-08-08T16:39:24.842328Z",
     "iopub.status.idle": "2024-08-08T16:39:24.848506Z",
     "shell.execute_reply": "2024-08-08T16:39:24.847682Z"
    },
    "papermill": {
     "duration": 0.023412,
     "end_time": "2024-08-08T16:39:24.850445",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.827033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info('Started logging')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fafbd2",
   "metadata": {
    "papermill": {
     "duration": 0.014524,
     "end_time": "2024-08-08T16:39:24.880106",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.865582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b8df3",
   "metadata": {
    "papermill": {
     "duration": 0.014644,
     "end_time": "2024-08-08T16:39:24.909150",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.894506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Grid encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726e113",
   "metadata": {
    "papermill": {
     "duration": 0.015049,
     "end_time": "2024-08-08T16:39:24.939966",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.924917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are many ways to encode/format the grid as input to the LLM. In this section we are going to define several encoders so we can sistematically try them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8cc02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:24.971082Z",
     "iopub.status.busy": "2024-08-08T16:39:24.970365Z",
     "iopub.status.idle": "2024-08-08T16:39:24.975298Z",
     "shell.execute_reply": "2024-08-08T16:39:24.974426Z"
    },
    "papermill": {
     "duration": 0.022308,
     "end_time": "2024-08-08T16:39:24.977214",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.954906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GridEncoder(ABC):\n",
    "    @abstractmethod\n",
    "    def to_text(self, grid):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def to_grid(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39667130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.007200Z",
     "iopub.status.busy": "2024-08-08T16:39:25.006752Z",
     "iopub.status.idle": "2024-08-08T16:39:25.011528Z",
     "shell.execute_reply": "2024-08-08T16:39:25.010724Z"
    },
    "papermill": {
     "duration": 0.021965,
     "end_time": "2024-08-08T16:39:25.013419",
     "exception": false,
     "start_time": "2024-08-08T16:39:24.991454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_grid = np.eye(3, dtype=int).tolist()\n",
    "\n",
    "def test_translator(translator):\n",
    "    assert sample_grid == translator.to_grid(translator.to_text(sample_grid))\n",
    "    print(translator.to_text(sample_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350ebd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.043688Z",
     "iopub.status.busy": "2024-08-08T16:39:25.043403Z",
     "iopub.status.idle": "2024-08-08T16:39:25.049834Z",
     "shell.execute_reply": "2024-08-08T16:39:25.048984Z"
    },
    "papermill": {
     "duration": 0.024132,
     "end_time": "2024-08-08T16:39:25.052219",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.028087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MinimalGridEncoder(GridEncoder):\n",
    "    @staticmethod\n",
    "    def to_text(grid):\n",
    "        text = '\\n'.join([''.join([str(x) for x in line]) for line in grid])\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_grid(text):\n",
    "        lines = text.strip().splitlines()\n",
    "        grid = [[int(x) for x in line] for line in lines]\n",
    "        return grid\n",
    "        \n",
    "test_translator(MinimalGridEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b25770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.082607Z",
     "iopub.status.busy": "2024-08-08T16:39:25.082315Z",
     "iopub.status.idle": "2024-08-08T16:39:25.089246Z",
     "shell.execute_reply": "2024-08-08T16:39:25.088274Z"
    },
    "papermill": {
     "duration": 0.024872,
     "end_time": "2024-08-08T16:39:25.091626",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.066754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GridWithSeparationEncoder(GridEncoder):\n",
    "    def __init__(self, split_symbol):\n",
    "        self.split_symbol = split_symbol\n",
    "\n",
    "    def to_text(self, grid):\n",
    "        text = '\\n'.join([self.split_symbol.join([str(x) for x in line]) for line in grid])\n",
    "        return text\n",
    "    \n",
    "    def to_grid(self, text):\n",
    "        lines = text.strip().splitlines()\n",
    "        grid = [[int(x) for x in line.split(self.split_symbol)] for line in lines]\n",
    "        return grid\n",
    "        \n",
    "test_translator(GridWithSeparationEncoder('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b755d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.123301Z",
     "iopub.status.busy": "2024-08-08T16:39:25.122589Z",
     "iopub.status.idle": "2024-08-08T16:39:25.129622Z",
     "shell.execute_reply": "2024-08-08T16:39:25.128724Z"
    },
    "papermill": {
     "duration": 0.025185,
     "end_time": "2024-08-08T16:39:25.132122",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.106937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GridCodeBlockEncoder(GridEncoder):\n",
    "    def __init__(self, base_encoder):\n",
    "        self.encoder = base_encoder\n",
    "    \n",
    "    def to_text(self, grid):\n",
    "        text = f'```grid\\n{self.encoder.to_text(grid)}\\n```'\n",
    "        return text\n",
    "    \n",
    "    def to_grid(self, text):\n",
    "        grid_text = text.split('```grid\\n')[1].split('\\n```')[0]\n",
    "        grid = self.encoder.to_grid(grid_text)\n",
    "        return grid\n",
    "        \n",
    "test_translator(GridCodeBlockEncoder(MinimalGridEncoder()))\n",
    "\n",
    "test_translator(GridCodeBlockEncoder(GridWithSeparationEncoder('|')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f29426",
   "metadata": {
    "papermill": {
     "duration": 0.01579,
     "end_time": "2024-08-08T16:39:25.162949",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.147159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29aab1",
   "metadata": {
    "papermill": {
     "duration": 0.014656,
     "end_time": "2024-08-08T16:39:25.192876",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.178220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are also many ways to build a prompt for the ARC challenge. The class that builds the prompt will receive a grid encoder as input, this way we can try different prompts with different grid encoders. \n",
    "The class that builds the prompts needs to be also capable of parsing the response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d6bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.223809Z",
     "iopub.status.busy": "2024-08-08T16:39:25.223022Z",
     "iopub.status.idle": "2024-08-08T16:39:25.228254Z",
     "shell.execute_reply": "2024-08-08T16:39:25.227445Z"
    },
    "papermill": {
     "duration": 0.022863,
     "end_time": "2024-08-08T16:39:25.230337",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.207474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PromptCreator(ABC):\n",
    "    def __init__(self, grid_encoder: GridEncoder):\n",
    "        self.grid_encoder = grid_encoder\n",
    "    \n",
    "    @abstractmethod\n",
    "    def create_task_prompts(self, task):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def parse_response(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8352f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.261074Z",
     "iopub.status.busy": "2024-08-08T16:39:25.260794Z",
     "iopub.status.idle": "2024-08-08T16:39:25.270631Z",
     "shell.execute_reply": "2024-08-08T16:39:25.269787Z"
    },
    "papermill": {
     "duration": 0.027444,
     "end_time": "2024-08-08T16:39:25.272541",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.245097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimplePromptCreator(PromptCreator):\n",
    "    def __init__(self, grid_encoder):\n",
    "        super().__init__(grid_encoder)\n",
    "    \n",
    "    def create_task_prompts(self, task):        \n",
    "        train_samples = [{key: self.grid_encoder.to_text(grid) for key, grid in sample.items()} for sample in task['train']]     \n",
    "        prompts = []\n",
    "        for test_sample in task['test']:\n",
    "            user_message = prompt_template.render(train_samples=train_samples, \n",
    "                                                  test_input=self.grid_encoder.to_text(test_sample['input']))\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_message},\n",
    "                        {\"role\": \"assistant\", \"content\": \"\"\"### Output\\n```grid\\n\"\"\"}]\n",
    "            # TODO: add start of assistant reply\n",
    "            prompt = tokenizer.apply_chat_template(messages,\n",
    "                                                   tokenize=False,\n",
    "                                                   add_generation_prompt=False)\n",
    "            prompts.append(remove_assistant_ending(prompt))\n",
    "        return prompts\n",
    "    \n",
    "    def parse_response(self, text):\n",
    "        return self.grid_encoder.to_grid('```grid\\n' + text)\n",
    "    \n",
    "    \n",
    "def remove_assistant_ending(text):\n",
    "    \"\"\"\n",
    "phi-3\n",
    "\n",
    "<|assistant|>\n",
    "### Output\n",
    "```grid\n",
    "<|end|>\n",
    "<|endoftext|>\n",
    "\n",
    "llama 3.1\n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "### Output\n",
    "```grid<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\"\n",
    "    if 'llama' in cfg.model_path:\n",
    "        split_text = '<|eot_id|>'\n",
    "    elif 'Qwen' in cfg.model_path:\n",
    "        split_text = '<|im_end|>'\n",
    "    else:\n",
    "        split_text = '<|end|>'\n",
    "    return split_text.join(text.split(split_text)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf7968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.303046Z",
     "iopub.status.busy": "2024-08-08T16:39:25.302394Z",
     "iopub.status.idle": "2024-08-08T16:39:25.309373Z",
     "shell.execute_reply": "2024-08-08T16:39:25.308586Z"
    },
    "papermill": {
     "duration": 0.024234,
     "end_time": "2024-08-08T16:39:25.311357",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.287123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_sample_prompt(data, prompt_creator):\n",
    "    prompts = [prompt_creator.create_task_prompts(task)[0] for task in data.values()]\n",
    "    prompts = sorted(prompts, key=lambda x: len(x))\n",
    "    pretty_print_prompt(prompts[0])\n",
    "    \n",
    "def pretty_print_prompt(text, default_color='black'):\n",
    "    color = default_color\n",
    "    attrs = None\n",
    "    for line in text.splitlines():\n",
    "        if line.startswith('<|assistant|>'):\n",
    "            color = 'blue'\n",
    "        elif line.startswith('<|user|>'):\n",
    "            color = default_color\n",
    "        elif line.startswith('<|system|>'):\n",
    "            color = 'green'\n",
    "        if line.startswith('<'):\n",
    "            attrs = ['bold']\n",
    "        else:\n",
    "            attrs = None\n",
    "        print(colored(line, color, attrs=attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d57bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.342578Z",
     "iopub.status.busy": "2024-08-08T16:39:25.342303Z",
     "iopub.status.idle": "2024-08-08T16:39:25.348066Z",
     "shell.execute_reply": "2024-08-08T16:39:25.347283Z"
    },
    "papermill": {
     "duration": 0.023508,
     "end_time": "2024-08-08T16:39:25.349878",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.326370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_input_token_length_distribution(data, prompt_creator):\n",
    "    prompts = []\n",
    "    for task in data.values():\n",
    "        prompts.extend(prompt_creator.create_task_prompts(task))\n",
    "    token_length_distribution = [len(tokenizer.tokenize(prompt)) for prompt in tqdm(prompts)]\n",
    "    plt.title('Prompt token length distribution')\n",
    "    plt.hist(token_length_distribution)\n",
    "    plt.xlabel('n tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d9896",
   "metadata": {
    "papermill": {
     "duration": 0.014577,
     "end_time": "2024-08-08T16:39:25.379164",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.364587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0635d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.410761Z",
     "iopub.status.busy": "2024-08-08T16:39:25.410101Z",
     "iopub.status.idle": "2024-08-08T16:39:25.418605Z",
     "shell.execute_reply": "2024-08-08T16:39:25.417819Z"
    },
    "papermill": {
     "duration": 0.026647,
     "end_time": "2024-08-08T16:39:25.420611",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.393964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_text = f\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import shutil\n",
    "\n",
    "base_model_path = '{cfg.model_path}'\n",
    "lora_path = '{cfg.lora_path}'\n",
    "output_path = '{cfg.merged_model_path}'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_path, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "if 'llama' in '{cfg.model_path}':\n",
    "    tokenizer.add_special_tokens(dict(pad_token='<|pad|>'))\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, lora_path)\n",
    "merged_model = model.merge_and_unload()\n",
    "print('Saving the merged model to the output path')\n",
    "merged_model.save_pretrained(output_path)\n",
    "\n",
    "for filepath in glob.glob(os.path.join(base_model_path, '*')):\n",
    "    dst = os.path.join(output_path, os.path.basename(filepath))\n",
    "    if not os.path.exists(dst):\n",
    "        print('Copying', filepath)\n",
    "        shutil.copy(filepath, dst)\n",
    "\n",
    "print('Done!')\n",
    "\"\"\"\n",
    "\n",
    "if not is_dry_run and cfg.merged_model_path is not None and not os.path.exists(cfg.merged_model_path):\n",
    "    with open('merge_lora.py', 'w') as f:\n",
    "        f.write(script_text)\n",
    "    !python merge_lora.py\n",
    "    os.remove('merge_lora.py')\n",
    "elif cfg.merged_model_path is not None and os.path.exists(cfg.merged_model_path):\n",
    "    print(f'Merged model already exists: {cfg.merged_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c333197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.451921Z",
     "iopub.status.busy": "2024-08-08T16:39:25.451355Z",
     "iopub.status.idle": "2024-08-08T16:39:25.457604Z",
     "shell.execute_reply": "2024-08-08T16:39:25.456642Z"
    },
    "papermill": {
     "duration": 0.02411,
     "end_time": "2024-08-08T16:39:25.459821",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.435711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_dry_run:\n",
    "    model_path = cfg.merged_model_path or cfg.model_path\n",
    "    print(f'Loading {model_path}')\n",
    "    llm = LLM(model=model_path,\n",
    "              trust_remote_code=True, \n",
    "              dtype='half', \n",
    "              tensor_parallel_size=2, # to use 2 gpus\n",
    "              max_model_len=cfg.max_model_len,\n",
    "              #kv_cache_dtype='fp8_e5m2', I have disabled kv cache quantization because it is hurtful\n",
    "              enforce_eager=True, # without this 13.9GB of memory is used on each GPU, with this is 13.3GB,\n",
    "              disable_log_stats=True,\n",
    "             )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model_path)\n",
    "    for number in '0123456789':\n",
    "        print(f'{number}: {[key for key in tokenizer.get_vocab().keys() if number in key and not key.startswith(\"<\")]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327ad52",
   "metadata": {
    "papermill": {
     "duration": 0.015389,
     "end_time": "2024-08-08T16:39:25.490849",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.475460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The tokenizer from phi-3 encodes each digit indepently, it does not group numbers such as 10 or 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e8dac",
   "metadata": {
    "papermill": {
     "duration": 0.01577,
     "end_time": "2024-08-08T16:39:25.524060",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.508290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b62954",
   "metadata": {
    "papermill": {
     "duration": 0.015799,
     "end_time": "2024-08-08T16:39:25.556001",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.540202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need data augmentation to make multiple predictions for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee1b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.589905Z",
     "iopub.status.busy": "2024-08-08T16:39:25.589052Z",
     "iopub.status.idle": "2024-08-08T16:39:25.602047Z",
     "shell.execute_reply": "2024-08-08T16:39:25.601245Z"
    },
    "papermill": {
     "duration": 0.032147,
     "end_time": "2024-08-08T16:39:25.604176",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.572029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataAugmentation():\n",
    "    def __init__(self, flip, n_rot90):\n",
    "        self.flip = flip\n",
    "        self.n_rot90 = n_rot90\n",
    "        \n",
    "    def augment_task(self, task):\n",
    "        augmented_task = dict()\n",
    "        for partition, samples in task.items():\n",
    "            augmented_task[partition] = [{name:self.augment_grid(grid) for name,grid in sample.items()} for sample in samples]\n",
    "        return augmented_task\n",
    "    \n",
    "    def augment_grid(self, grid):\n",
    "        grid = np.array(grid)\n",
    "        if self.flip:\n",
    "            grid = np.flip(grid, axis=1)\n",
    "        grid = np.rot90(grid, k=self.n_rot90)\n",
    "        return grid.tolist()\n",
    "    \n",
    "    def revert_augmentation(self, grid):\n",
    "        grid = np.array(grid)\n",
    "        grid = np.rot90(grid, k=-self.n_rot90)\n",
    "        if self.flip:\n",
    "            grid = np.flip(grid, axis=1)\n",
    "        return grid.tolist()\n",
    "\n",
    "\n",
    "for flip in [True, False]:\n",
    "    for n_rot90 in range(4):\n",
    "        data_augmentation = DataAugmentation(flip, n_rot90)\n",
    "        assert sample_grid == data_augmentation.revert_augmentation(data_augmentation.augment_grid(sample_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c7aaa",
   "metadata": {
    "papermill": {
     "duration": 0.01559,
     "end_time": "2024-08-08T16:39:25.635883",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.620293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2308287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.668576Z",
     "iopub.status.busy": "2024-08-08T16:39:25.667887Z",
     "iopub.status.idle": "2024-08-08T16:39:25.677944Z",
     "shell.execute_reply": "2024-08-08T16:39:25.677035Z"
    },
    "papermill": {
     "duration": 0.02885,
     "end_time": "2024-08-08T16:39:25.680113",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.651263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_task(task):\n",
    "    samples = task['train'] + task['test']\n",
    "    for plot_idx, sample in enumerate(samples):\n",
    "        plt.subplot(2, len(samples), plot_idx + 1)\n",
    "        plot_grid(sample['input'])\n",
    "        if 'output' in sample:\n",
    "            plt.subplot(2, len(samples), plot_idx + 1 + len(samples))\n",
    "            plot_grid(sample['output'])\n",
    "            \n",
    "def plot_grids(grids):\n",
    "    for plot_idx, grid in enumerate(grids):\n",
    "        plt.subplot(1, len(grids), plot_idx + 1)\n",
    "        plot_grid(grid)\n",
    "            \n",
    "def plot_grid(grid):\n",
    "    grid = np.array(grid)\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    plt.imshow(grid, cmap=cmap, norm=norm)\n",
    "    plt.grid(True,which='both',color='lightgrey', linewidth=0.5) \n",
    "    plt.xticks(np.arange(-0.5, grid.shape[1]), [])\n",
    "    plt.yticks(np.arange(-0.5, grid.shape[0]), [])\n",
    "    plt.xlim(-0.5, grid.shape[1]-0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df7dc3",
   "metadata": {
    "papermill": {
     "duration": 0.015881,
     "end_time": "2024-08-08T16:39:25.712144",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.696263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27c48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.744583Z",
     "iopub.status.busy": "2024-08-08T16:39:25.744115Z",
     "iopub.status.idle": "2024-08-08T16:39:25.749726Z",
     "shell.execute_reply": "2024-08-08T16:39:25.748814Z"
    },
    "papermill": {
     "duration": 0.023469,
     "end_time": "2024-08-08T16:39:25.751616",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.728147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_number_of_predictions_per_task(data, texts):\n",
    "    number_of_predictions = dict()\n",
    "    for task_id, task in data.items():\n",
    "        number_of_predictions[task_id] = len(texts[task_id]['responses'])/len(task['test'])\n",
    "    plt.title('Distribution of the number of predictions per task')\n",
    "    plt.hist(number_of_predictions.values(), bins=np.arange(1.5, 9))\n",
    "    plt.xlabel('number of predictions')\n",
    "    plt.ylabel('count')\n",
    "    return number_of_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34244aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.782178Z",
     "iopub.status.busy": "2024-08-08T16:39:25.781559Z",
     "iopub.status.idle": "2024-08-08T16:39:25.798353Z",
     "shell.execute_reply": "2024-08-08T16:39:25.797491Z"
    },
    "papermill": {
     "duration": 0.034024,
     "end_time": "2024-08-08T16:39:25.800275",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.766251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, solutions):\n",
    "    \"\"\"\n",
    "    Computes the following metrics:\n",
    "    \n",
    "    - Accuracy\n",
    "    - Correct pixels\n",
    "    - Correct size\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    for task_id, task_ground_truth in ground_truth.items():\n",
    "        task_metrics = []\n",
    "        plot_task(data[task_id]); plt.suptitle(f'{task_id}'); plt.show()\n",
    "        for idx, correct_grid in enumerate(task_ground_truth):\n",
    "            predicted_grids = list(solutions[task_id][idx].values())\n",
    "            predicted_grids = [grid for grid in predicted_grids if grid]\n",
    "            \n",
    "            task_metrics.append(evaluate_grid(correct_grid, predicted_grids))\n",
    "            print_metrics(task_metrics[-1], f'{task_id}_{idx}')\n",
    "            plot_grids([correct_grid] + predicted_grids)\n",
    "            plt.suptitle(f'{task_id}_{idx}')\n",
    "            plt.show()\n",
    "        metrics.append(average_metrics(task_metrics))\n",
    "    print('\\n'*3 + '# Aggregated metrics:')\n",
    "    print_metrics(average_metrics(metrics))\n",
    "    save_metrics(metrics, solutions)\n",
    "    plot_metrics_distribution(metrics)\n",
    "    print_metrics(average_metrics(metrics))\n",
    "    \n",
    "def plot_metrics_distribution(metrics):\n",
    "    for key in metrics[0]:\n",
    "        values = [x[key] for x in metrics]\n",
    "        plt.title(f'Distribution of {key}')\n",
    "        plt.hist(values, bins=np.linspace(0, 1, 10))\n",
    "        plt.xlabel(key)\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "    \n",
    "def average_metrics(metrics):\n",
    "    averaged_metrics = dict()\n",
    "    for key in metrics[0]:\n",
    "        averaged_metrics[key] = np.mean([x[key] for x in metrics])\n",
    "    return averaged_metrics\n",
    "        \n",
    "def save_metrics(metrics, solutions):\n",
    "    formatted_metrics = dict(global_metrics=average_metrics(metrics))\n",
    "    for task_id, task_metrics in zip(solutions, metrics):\n",
    "        formatted_metrics[task_id] = task_metrics\n",
    "    with open('metrics.json', 'w') as f:\n",
    "        json.dump(formatted_metrics, f)\n",
    "\n",
    "def print_metrics(metrics, prefix=''):\n",
    "    text = f'{prefix}'\n",
    "    for key, value in metrics.items():\n",
    "        text += f'{key}: {value*100:.1f}%\\t'\n",
    "    print(text)\n",
    "\n",
    "    \n",
    "def evaluate_grid(correct_grid, predicted_grids):\n",
    "    correct_grid = np.array(correct_grid)\n",
    "    metrics = dict(accuracy=0, correct_pixels=0, correct_size=0, unanswered=(2 - len(predicted_grids))/2)\n",
    "    for predicted_grid in predicted_grids:\n",
    "        predicted_grid = np.array(predicted_grid)\n",
    "        if correct_grid.shape == predicted_grid.shape:\n",
    "            metrics['accuracy'] = max(metrics['accuracy'], np.all(predicted_grid == correct_grid))\n",
    "            metrics['correct_pixels'] = max(metrics['correct_pixels'], np.mean(predicted_grid == correct_grid))\n",
    "            metrics['correct_size'] = max(metrics['correct_size'], correct_grid.shape == predicted_grid.shape)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d97c4",
   "metadata": {
    "papermill": {
     "duration": 0.015459,
     "end_time": "2024-08-08T16:39:25.831646",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.816187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016e1fc",
   "metadata": {
    "papermill": {
     "duration": 0.015496,
     "end_time": "2024-08-08T16:39:25.862494",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.846998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to generate 2 different predictions for each task. The model could fail to generate a prediction, or the parsing can fail... Thus we need a method that is robust to fails.\n",
    "\n",
    "One way to solve this would be to use data augmentation. By applying rotations and flips we could generate up to 8 variations of each task. So we could try with different data augmentations until we have 2 predictions for each task. Another alternative would be to make inference with the 8 variations and use majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd77f17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.894690Z",
     "iopub.status.busy": "2024-08-08T16:39:25.893937Z",
     "iopub.status.idle": "2024-08-08T16:39:25.905858Z",
     "shell.execute_reply": "2024-08-08T16:39:25.904869Z"
    },
    "papermill": {
     "duration": 0.030139,
     "end_time": "2024-08-08T16:39:25.907860",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.877721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve_task(task_id, task, prompt_creator, sampling_params):\n",
    "    data_augmentation_params = product([False, True], [0, 1, 2, 3])\n",
    "    solution = {task_id:[{\"attempt_1\": [], \"attempt_2\": []} for _ in task['test']]}\n",
    "    texts = dict(prompts=[], responses=[], exceptions=[])\n",
    "    for flip, n_rot90 in islice(data_augmentation_params, cfg.max_predictions_per_task):\n",
    "        data_augmentation = DataAugmentation(flip, n_rot90)\n",
    "        augmented_task = data_augmentation.augment_task(task)\n",
    "        prompts = prompt_creator.create_task_prompts(augmented_task)\n",
    "        outputs = llm.generate(prompts, sampling_params, use_tqdm=False)\n",
    "        responses = [output.outputs[0].text for output in outputs]\n",
    "        for idx, response in enumerate(responses):\n",
    "            try:\n",
    "                augmented_grid = prompt_creator.parse_response(response)\n",
    "                grid = data_augmentation.revert_augmentation(augmented_grid)\n",
    "                if not solution[task_id][idx][\"attempt_1\"]:\n",
    "                    solution[task_id][idx][\"attempt_1\"] = grid\n",
    "                elif solution[task_id][idx][\"attempt_1\"] != grid and not solution[task_id][idx][\"attempt_2\"]:\n",
    "                    solution[task_id][idx][\"attempt_2\"] = grid\n",
    "            except Exception as e:\n",
    "                print(f'Exception when parsing response from {task_id}: {e}')\n",
    "                texts['exceptions'].append(str(e))\n",
    "        texts['prompts'].append(prompts)\n",
    "        texts['responses'].append(responses)\n",
    "        if is_solution_done(solution):\n",
    "            break\n",
    "    return solution, {task_id:texts}\n",
    "\n",
    "def is_solution_done(solution):\n",
    "    for task_id, predictions in solution.items():\n",
    "        for prediction in predictions:\n",
    "            for grid in prediction.values():\n",
    "                if not grid:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe1ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.940776Z",
     "iopub.status.busy": "2024-08-08T16:39:25.940446Z",
     "iopub.status.idle": "2024-08-08T16:39:25.946286Z",
     "shell.execute_reply": "2024-08-08T16:39:25.945429Z"
    },
    "papermill": {
     "duration": 0.024327,
     "end_time": "2024-08-08T16:39:25.948068",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.923741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(data, prompt_creator, sampling_params):\n",
    "    solutions, texts = dict(), dict()\n",
    "    for idx, (task_id, task) in tqdm(enumerate(data.items()), total=len(data), desc='Solving tasks'):\n",
    "        logging.info(f'Solving {task_id}, {idx+1}/{len(data)}')\n",
    "        task_solution, task_texts = solve_task(task_id, task, prompt_creator, sampling_params)\n",
    "        solutions.update(task_solution)\n",
    "        texts.update(task_texts)\n",
    "    return solutions, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f58627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:25.978461Z",
     "iopub.status.busy": "2024-08-08T16:39:25.978027Z",
     "iopub.status.idle": "2024-08-08T16:39:26.017937Z",
     "shell.execute_reply": "2024-08-08T16:39:26.016976Z"
    },
    "papermill": {
     "duration": 0.056987,
     "end_time": "2024-08-08T16:39:26.019898",
     "exception": false,
     "start_time": "2024-08-08T16:39:25.962911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(cfg.dataset_path) as f:\n",
    "    data = json.load(f)\n",
    "if cfg.n_tasks is not None:\n",
    "    data = dict(islice(data.items(), cfg.n_tasks))\n",
    "print(f'There are {len(data)} tasks to solve.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea5696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.050234Z",
     "iopub.status.busy": "2024-08-08T16:39:26.049958Z",
     "iopub.status.idle": "2024-08-08T16:39:26.054174Z",
     "shell.execute_reply": "2024-08-08T16:39:26.053370Z"
    },
    "papermill": {
     "duration": 0.021474,
     "end_time": "2024-08-08T16:39:26.056033",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.034559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_dry_run:\n",
    "    prompt_creator = SimplePromptCreator(GridCodeBlockEncoder(MinimalGridEncoder()))\n",
    "    print_sample_prompt(data, prompt_creator)\n",
    "    plot_input_token_length_distribution(data, prompt_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45399d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.086273Z",
     "iopub.status.busy": "2024-08-08T16:39:26.085853Z",
     "iopub.status.idle": "2024-08-08T16:39:26.091059Z",
     "shell.execute_reply": "2024-08-08T16:39:26.090317Z"
    },
    "papermill": {
     "duration": 0.022283,
     "end_time": "2024-08-08T16:39:26.092872",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.070589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_dry_run:\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(dict(dry_run=True), f)\n",
    "else:\n",
    "    sampling_params = SamplingParams(n=1, **cfg.sampling_params)\n",
    "    solutions, texts = inference(data, prompt_creator, sampling_params)\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(solutions, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec8bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.123609Z",
     "iopub.status.busy": "2024-08-08T16:39:26.123356Z",
     "iopub.status.idle": "2024-08-08T16:39:26.127248Z",
     "shell.execute_reply": "2024-08-08T16:39:26.126537Z"
    },
    "papermill": {
     "duration": 0.021095,
     "end_time": "2024-08-08T16:39:26.129054",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.107959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_dry_run:\n",
    "    number_of_predictions_per_task = analyze_number_of_predictions_per_task(data, texts)\n",
    "    number_of_predictions_per_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c8165",
   "metadata": {
    "papermill": {
     "duration": 0.014365,
     "end_time": "2024-08-08T16:39:26.157878",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.143513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10592076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.189422Z",
     "iopub.status.busy": "2024-08-08T16:39:26.188909Z",
     "iopub.status.idle": "2024-08-08T16:39:26.195370Z",
     "shell.execute_reply": "2024-08-08T16:39:26.194694Z"
    },
    "papermill": {
     "duration": 0.023856,
     "end_time": "2024-08-08T16:39:26.197218",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.173362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_path = cfg.dataset_path.replace('challenges.json', 'solutions.json')\n",
    "if os.path.exists(ground_truth_path):\n",
    "    with open(ground_truth_path, 'r') as f:\n",
    "        ground_truth = json.load(f)\n",
    "    ground_truth = {key: ground_truth[key] for key in solutions}\n",
    "    evaluate(ground_truth, solutions)\n",
    "    \n",
    "    with open('texts.json', 'w') as f:\n",
    "        json.dump(texts, f)\n",
    "    with open('number_of_predictions_per_task.json', 'w') as f:\n",
    "        json.dump(number_of_predictions_per_task, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a5d7b",
   "metadata": {
    "papermill": {
     "duration": 0.014381,
     "end_time": "2024-08-08T16:39:26.226585",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.212204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2630c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.257311Z",
     "iopub.status.busy": "2024-08-08T16:39:26.256879Z",
     "iopub.status.idle": "2024-08-08T16:39:26.262386Z",
     "shell.execute_reply": "2024-08-08T16:39:26.261542Z"
    },
    "papermill": {
     "duration": 0.022956,
     "end_time": "2024-08-08T16:39:26.264236",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.241280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clear_vllm_gpu_memory():\n",
    "    global llm\n",
    "    # https://github.com/vllm-project/vllm/issues/1908\n",
    "    from vllm.distributed.parallel_state import destroy_model_parallel, destroy_distributed_environment\n",
    "    import torch\n",
    "    import gc\n",
    "    destroy_model_parallel()\n",
    "    destroy_distributed_environment()\n",
    "    del llm.llm_engine.model_executor\n",
    "    del llm\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if not is_dry_run:\n",
    "    clear_vllm_gpu_memory()\n",
    "    if cfg.merged_model_path is not None:\n",
    "        shutil.rmtree(cfg.merged_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a82a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T16:39:26.295587Z",
     "iopub.status.busy": "2024-08-08T16:39:26.294929Z",
     "iopub.status.idle": "2024-08-08T16:39:27.320692Z",
     "shell.execute_reply": "2024-08-08T16:39:27.319498Z"
    },
    "papermill": {
     "duration": 1.044279,
     "end_time": "2024-08-08T16:39:27.323227",
     "exception": false,
     "start_time": "2024-08-08T16:39:26.278948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!rm -rf *\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa0d00",
   "metadata": {
    "papermill": {
     "duration": 0.015294,
     "end_time": "2024-08-08T16:39:27.354821",
     "exception": false,
     "start_time": "2024-08-08T16:39:27.339527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060f0d5",
   "metadata": {
    "papermill": {
     "duration": 0.014432,
     "end_time": "2024-08-08T16:39:27.384159",
     "exception": false,
     "start_time": "2024-08-08T16:39:27.369727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- [x] I need to read the code and understand everything before refactoring. \n",
    "- [x] Add logging, some evaluations on the previous notebook took more than 12 hours and I didn't have observability\n",
    "- [x] Remove all few-shot prompt inheritance from the previous notebook\n",
    "- [x] ~~Allow to use LoRAs~~ It does not work with VLLM, maybe is due to the GPU. Instead I'm merging the model\n",
    "- [x] Allow to merge a model with its LoRA (it should be faster)\n",
    "- [x] Check and copy improvements done on local evaluation\n",
    "- [x] Verify that I get the same results as in local evaluation\n",
    "- [ ] Wait for free GPU\n",
    "- [ ] Better logging of parsing errors, f.e. print the shape of the list.\n",
    "- [ ] Add an option to do test-time fine-tuning\n",
    "- [ ] Can I speedup inference? By making multiple requests in parallel, or running the server in another thread.\n",
    "- [ ] Can I create a more compact visualization of the tasks and predictions?\n",
    "- [ ] More flexible configuration and prompt specification. This should be compatible with the training script. Maybe the code should be shared.\n",
    "- [ ] How to handle the case where I predict the grid shape before the grid?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    },
    {
     "sourceId": 191546747,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 1902,
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 90791,
     "modelInstanceId": 65946,
     "sourceId": 78461,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 81881,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 98761,
     "modelInstanceId": 73938,
     "sourceId": 88043,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.675329,
   "end_time": "2024-08-08T16:39:27.717020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-08T16:39:20.041691",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
